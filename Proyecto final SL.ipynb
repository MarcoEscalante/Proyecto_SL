{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIVERSIDAD GALILEO**\n",
    "\n",
    "**Marco Vinicio Escalante Lara**\n",
    "\n",
    "Carnet: **19001148**\n",
    "\n",
    "# Proyecto Statistical Learning I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos y descripción de información\n",
    "Para ver con que información contamos realizamos una muestra de los primeros diez registros de la tabla. Así como también trabajamos una descripción de las variables, para saber su distribución entre otros e iniciar el trabajo con nuestras variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   PassengerId                                               Name   Age  \\\n",
       " 0            1                            Braund, Mr. Owen Harris  22.0   \n",
       " 1            2  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0   \n",
       " 2            3                             Heikkinen, Miss. Laina  26.0   \n",
       " 3            4       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0   \n",
       " 4            5                           Allen, Mr. William Henry  35.0   \n",
       " 5            6                                   Moran, Mr. James   NaN   \n",
       " 6            7                            McCarthy, Mr. Timothy J  54.0   \n",
       " 7            8                     Palsson, Master. Gosta Leonard   2.0   \n",
       " 8            9  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  27.0   \n",
       " 9           10                Nasser, Mrs. Nicholas (Adele Achem)  14.0   \n",
       " \n",
       "    SibSp  Parch            Ticket     Fare Cabin Embarked passenger_class  \\\n",
       " 0      1      0         A/5 21171   7.2500   NaN        S           Lower   \n",
       " 1      1      0          PC 17599  71.2833   C85        C           Upper   \n",
       " 2      0      0  STON/O2. 3101282   7.9250   NaN        S           Lower   \n",
       " 3      1      0            113803  53.1000  C123        S           Upper   \n",
       " 4      0      0            373450   8.0500   NaN        S           Lower   \n",
       " 5      0      0            330877   8.4583   NaN        Q           Lower   \n",
       " 6      0      0             17463  51.8625   E46        S           Upper   \n",
       " 7      3      1            349909  21.0750   NaN        S           Lower   \n",
       " 8      0      2            347742  11.1333   NaN        S           Lower   \n",
       " 9      1      0            237736  30.0708   NaN        C          Middle   \n",
       " \n",
       "   passenger_sex passenger_survived  \n",
       " 0             M                  N  \n",
       " 1             F                  Y  \n",
       " 2             F                  Y  \n",
       " 3             F                  Y  \n",
       " 4             M                  N  \n",
       " 5             M                  N  \n",
       " 6             M                  N  \n",
       " 7             M                  N  \n",
       " 8             F                  Y  \n",
       " 9             F                  Y  ,\n",
       "        PassengerId         Age       SibSp       Parch        Fare\n",
       " count   891.000000  714.000000  891.000000  891.000000  891.000000\n",
       " mean    446.000000   29.699118    0.523008    0.381594   32.204208\n",
       " std     257.353842   14.526497    1.102743    0.806057   49.693429\n",
       " min       1.000000    0.420000    0.000000    0.000000    0.000000\n",
       " 25%     223.500000   20.125000    0.000000    0.000000    7.910400\n",
       " 50%     446.000000   28.000000    0.000000    0.000000   14.454200\n",
       " 75%     668.500000   38.000000    1.000000    0.000000   31.000000\n",
       " max     891.000000   80.000000    8.000000    6.000000  512.329200)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titanic = pd.read_csv(\"titanic.csv\")\n",
    "Titanic.head(10) ,Titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de variables y limpieza\n",
    "\n",
    "### Por el tipo de datos que tenemos vamos a trabajar con los siguientes (One hot encoding):\n",
    "\n",
    "**Edad** --> Es un número discreto, si tiene NA o NULL le colocaremos la mediana de los datos.\n",
    "\n",
    "**SibSP** --> Es un número discreto, que indica la cantidad de hermanos/esposas que estaban a bordo por pasajero.\n",
    "\n",
    "**Parch** --> Es un número discreto, que indica la cantidad de padres/hijos que estaban a bordo por pasajero.\n",
    "\n",
    "**Fare** --> Es un número continuo, que indica la tarifa que pago el pasajero.\n",
    "\n",
    "**Embarked** --> Es una letra, que se recodifico para tener una variable númerica, donde 1 significa puerta de embarque Cherbourg, 2 signficca puerta de embarque Queenstown y 3 puerta de embarque Southampton.\n",
    "\n",
    "**passenger_class** --> Es una palabra que indica en que clase viajan los pasajeros, 1 significa primera clase, 2 significa segunda clase y 3 tercera clase.\n",
    "\n",
    "**passenger_sex** --> Es una letra, que indica el sexo del pasajero, la cual reclasificamos en 0 para hombres y 1 para mujeres.\n",
    "\n",
    "La variable que queremos clasificar:\n",
    "\n",
    "**passenger_survived** --> Es una letra que indica si el pasajero sobrevivio o no, la cual reclasificamos con 1 para sobrevivio y 0 para no sobrevivio.   \n",
    "\n",
    "### Debido a que trabajamos Feature Engeenier no tomamos, las siguientes variables:\n",
    "\n",
    "**PassengerId** --> Ya que solo identifica a los pasajeros.\n",
    "\n",
    "**Ticket** --> Es una combinación numerica del ticket del pasajero\n",
    "\n",
    "**Name** --> Es el nombre del pasajero.\n",
    "\n",
    "**Cabin** --> Es el número de la cabina donde se hospedo el pasajero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sexo</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>passenger_class_Lower</th>\n",
       "      <th>passenger_class_Middle</th>\n",
       "      <th>passenger_class_Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch     Fare  Sexo  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "0  22.0      1      0   7.2500   0.0           0           0           1   \n",
       "1  38.0      1      0  71.2833   1.0           1           0           0   \n",
       "2  26.0      0      0   7.9250   1.0           0           0           1   \n",
       "3  35.0      1      0  53.1000   1.0           0           0           1   \n",
       "4  35.0      0      0   8.0500   0.0           0           0           1   \n",
       "\n",
       "   passenger_class_Lower  passenger_class_Middle  passenger_class_Upper  \n",
       "0                      1                       0                      0  \n",
       "1                      0                       0                      1  \n",
       "2                      1                       0                      0  \n",
       "3                      0                       0                      1  \n",
       "4                      1                       0                      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colocar la mediana a los NA de edad\n",
    "Titanic[\"Age\"] = Titanic[\"Age\"].fillna(Titanic[\"Age\"].median());\n",
    "Titanic[\"Age\"].isnull().sum()\n",
    "# Cambiar de letra a numero el sexo\n",
    "Titanic[\"Sexo\"] = (Titanic[\"passenger_sex\"] == 'F').astype(np.float)\n",
    "# Definiendo las variables\n",
    "target = [\"passenger_survived\"]\n",
    "numeric_fields = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Sexo\", \"Embarked\", \"passenger_class\"]\n",
    "y = (Titanic[target].values == 'Y').astype(np.float)\n",
    "# One hot encoding, cambiando variables categoricas a dummies\n",
    "X =  pd.get_dummies(Titanic[numeric_fields])\n",
    "\n",
    "# Muestra de la descripción de datos de nuestras variables a utilizar\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de entreno, validación y prueba\n",
    "\n",
    "Por medio de Sklearn, como sugerencia en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 11), (143, 11), (179, 11))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento, validación y de prueba \n",
    "X_entreno1, X_test, y_entreno1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Separación de los datos \n",
    "X_entreno, X_val, y_entreno, y_val = train_test_split(X_entreno1, y_entreno1, test_size=0.2, random_state=42)\n",
    "# Dimensiones de la muestra\n",
    "X_entreno.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión\n",
    "\n",
    "Arboles de decisión tomando los datos que trabajos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arbol_segmentacion(X_entreno, X_val, y_entreno, y_val, parametro): \n",
    "    arbol = tree.DecisionTreeClassifier(max_depth = parametro)\n",
    "    arbol = arbol.fit(X_entreno, y_entreno)\n",
    "    arbol.fit(X_entreno,y_entreno)\n",
    "    # Medidas de entreno y validación obtenidas por Sklearn\n",
    "    # Medidas de entreno\n",
    "    y_pred_e = arbol.predict(X_entreno)\n",
    "    y_pred_v = arbol.predict(X_val)\n",
    "    medidas_entreno = [mt.accuracy_score(y_entreno, y_pred_e, normalize=True), mt.f1_score(y_entreno, y_pred_e), \n",
    "                       mt.precision_score(y_entreno, y_pred_e), \n",
    "                       mt.recall_score(y_entreno, y_pred_e, average='weighted')]\n",
    "    medidas_validacion = [mt.accuracy_score(y_val, y_pred_v, normalize=True), mt.f1_score(y_val, y_pred_v), \n",
    "                          mt.precision_score(y_val, y_pred_v), \n",
    "                          mt.recall_score(y_val, y_pred_v, average='weighted')]\n",
    "    # Retorna el modelo y las medidas de entreno y validación\n",
    "    return arbol, medidas_entreno, medidas_validacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_entreno = []\n",
    "metricas_validacion = []\n",
    "profundidad_lista = [2, 3, 4, 5, 6, 7, 8, 9, 10, 20]\n",
    "for n in profundidad_lista: \n",
    "    _, metrica_e, metrica_v = arbol_segmentacion(X_entreno, X_val, y_entreno, y_val, n)\n",
    "    metricas_entreno.append(metrica_e)\n",
    "    metricas_validacion.append(metrica_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de las Metricas del Árbol\n",
    "\n",
    "A continuación se muestran los resultados de las metricas para el modelo de árboles de segmentación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profundidad</th>\n",
       "      <th>Accuracy_Entreno</th>\n",
       "      <th>f1_Entreno</th>\n",
       "      <th>Precision_Entreno</th>\n",
       "      <th>Recall_Entreno</th>\n",
       "      <th>Accuracy_Val</th>\n",
       "      <th>f1_Val</th>\n",
       "      <th>Precision_Val</th>\n",
       "      <th>Recall_Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.799649</td>\n",
       "      <td>0.650307</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.799649</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.833040</td>\n",
       "      <td>0.760705</td>\n",
       "      <td>0.816216</td>\n",
       "      <td>0.833040</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.832168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.838313</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.838313</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.839161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.855888</td>\n",
       "      <td>0.779570</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.855888</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.825175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.880492</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.880492</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.790210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.892794</td>\n",
       "      <td>0.839895</td>\n",
       "      <td>0.946746</td>\n",
       "      <td>0.892794</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.825175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.906854</td>\n",
       "      <td>0.860158</td>\n",
       "      <td>0.976048</td>\n",
       "      <td>0.906854</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.797203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.919156</td>\n",
       "      <td>0.878947</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.919156</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.926186</td>\n",
       "      <td>0.891192</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.926186</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.797203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>0.968974</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.790210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Profundidad  Accuracy_Entreno  f1_Entreno  Precision_Entreno  \\\n",
       "0          2.0          0.799649    0.650307           0.929825   \n",
       "1          3.0          0.833040    0.760705           0.816216   \n",
       "2          4.0          0.838313    0.770000           0.819149   \n",
       "3          5.0          0.855888    0.779570           0.906250   \n",
       "4          6.0          0.880492    0.817204           0.950000   \n",
       "5          7.0          0.892794    0.839895           0.946746   \n",
       "6          8.0          0.906854    0.860158           0.976048   \n",
       "7          9.0          0.919156    0.878947           0.994048   \n",
       "8         10.0          0.926186    0.891192           0.988506   \n",
       "9         20.0          0.977153    0.968974           0.980676   \n",
       "\n",
       "   Recall_Entreno  Accuracy_Val    f1_Val  Precision_Val  Recall_Val  \n",
       "0        0.799649      0.818182  0.723404       0.894737    0.818182  \n",
       "1        0.833040      0.832168  0.773585       0.820000    0.832168  \n",
       "2        0.838313      0.839161  0.785047       0.823529    0.839161  \n",
       "3        0.855888      0.825175  0.752475       0.844444    0.825175  \n",
       "4        0.880492      0.790210  0.705882       0.782609    0.790210  \n",
       "5        0.892794      0.825175  0.757282       0.829787    0.825175  \n",
       "6        0.906854      0.797203  0.712871       0.800000    0.797203  \n",
       "7        0.919156      0.818182  0.754717       0.800000    0.818182  \n",
       "8        0.926186      0.797203  0.728972       0.764706    0.797203  \n",
       "9        0.977153      0.790210  0.732143       0.732143    0.790210  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_arbol = pd.DataFrame(np.column_stack((profundidad_lista, np.array(metricas_entreno), \n",
    "                                                np.array(metricas_validacion))), \n",
    "                               columns = ['Profundidad', 'Accuracy_Entreno', 'f1_Entreno', 'Precision_Entreno', \n",
    "                                          'Recall_Entreno', 'Accuracy_Val', 'f1_Val', 'Precision_Val', \n",
    "                                          'Recall_Val'])\n",
    "resultado_arbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supor Vector Machine\n",
    "\n",
    "SVM tomando los datos que trabajos anteriormente, vamos a trabajar con un kernel Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_funcion(X_entreno, X_val, y_entreno, y_val, C_param): \n",
    "    svm_model = Pipeline([(\"scaler\", StandardScaler()), \n",
    "                          (\"svc\", SVC(C = C_param, kernel='rbf', tol = 0.001, max_iter = 5000))])\n",
    "    svm_model.fit(X_entreno, y_entreno.reshape(len(y_entreno), ))\n",
    "    # Medidas de entreno y validación obtenidas por Sklearn\n",
    "    # Medidas de entreno\n",
    "    y_pred_e = svm_model.predict(X_entreno)\n",
    "    y_pred_v = svm_model.predict(X_val)\n",
    "    medidas_entreno = [mt.accuracy_score(y_entreno, y_pred_e, normalize=True), \n",
    "                       mt.f1_score(y_entreno, y_pred_e), mt.precision_score(y_entreno, y_pred_e), \n",
    "                       mt.recall_score(y_entreno, y_pred_e, average='weighted')]\n",
    "    medidas_validacion = [mt.accuracy_score(y_val, y_pred_v, normalize=True), \n",
    "                          mt.f1_score(y_val, y_pred_v),  mt.precision_score(y_val, y_pred_v), \n",
    "                          mt.recall_score(y_val, y_pred_v, average='weighted')]\n",
    "    # Retorna el modelo y las medidas de entreno y validación\n",
    "    return svm_model, medidas_entreno, medidas_validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametro = [0.1, 1., 2., 3., 4., 5., 6., 7., 10., 15.]\n",
    "metricas_entreno = []\n",
    "metricas_validacion = []\n",
    "for n in parametro:\n",
    "    _, metrica_e, metrica_v = svm_funcion(X_entreno, X_val, y_entreno, y_val, n)\n",
    "    metricas_entreno.append(metrica_e.copy())\n",
    "    metricas_validacion.append(metrica_v.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parametro</th>\n",
       "      <th>Accuracy_Entreno</th>\n",
       "      <th>f1_Entreno</th>\n",
       "      <th>Precision_Entreno</th>\n",
       "      <th>Recall_Entreno</th>\n",
       "      <th>Accuracy_Val</th>\n",
       "      <th>f1_Val</th>\n",
       "      <th>Precision_Val</th>\n",
       "      <th>Recall_Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.808436</td>\n",
       "      <td>0.702997</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.808436</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.811189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.843585</td>\n",
       "      <td>0.756164</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.843585</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.839161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.843585</td>\n",
       "      <td>0.754821</td>\n",
       "      <td>0.907285</td>\n",
       "      <td>0.843585</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.847100</td>\n",
       "      <td>0.761644</td>\n",
       "      <td>0.908497</td>\n",
       "      <td>0.847100</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.839161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.848858</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.848858</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.839161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.850615</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.850615</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.839161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.854130</td>\n",
       "      <td>0.776280</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.854130</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.839161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.859402</td>\n",
       "      <td>0.786096</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.859402</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.832168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.871705</td>\n",
       "      <td>0.808399</td>\n",
       "      <td>0.911243</td>\n",
       "      <td>0.871705</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.811189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.869947</td>\n",
       "      <td>0.806283</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.869947</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.804196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parametro  Accuracy_Entreno  f1_Entreno  Precision_Entreno  Recall_Entreno  \\\n",
       "0        0.1          0.808436    0.702997           0.832258        0.808436   \n",
       "1        1.0          0.843585    0.756164           0.901961        0.843585   \n",
       "2        2.0          0.843585    0.754821           0.907285        0.843585   \n",
       "3        3.0          0.847100    0.761644           0.908497        0.847100   \n",
       "4        4.0          0.848858    0.763736           0.914474        0.848858   \n",
       "5        5.0          0.850615    0.767123           0.915033        0.850615   \n",
       "6        6.0          0.854130    0.776280           0.905660        0.854130   \n",
       "7        7.0          0.859402    0.786096           0.907407        0.859402   \n",
       "8       10.0          0.871705    0.808399           0.911243        0.871705   \n",
       "9       15.0          0.869947    0.806283           0.905882        0.869947   \n",
       "\n",
       "   Accuracy_Val    f1_Val  Precision_Val  Recall_Val  \n",
       "0      0.811189  0.737864       0.808511    0.811189  \n",
       "1      0.839161  0.772277       0.866667    0.839161  \n",
       "2      0.846154  0.780000       0.886364    0.846154  \n",
       "3      0.839161  0.772277       0.866667    0.839161  \n",
       "4      0.839161  0.772277       0.866667    0.839161  \n",
       "5      0.839161  0.772277       0.866667    0.839161  \n",
       "6      0.839161  0.772277       0.866667    0.839161  \n",
       "7      0.832168  0.764706       0.847826    0.832168  \n",
       "8      0.811189  0.742857       0.795918    0.811189  \n",
       "9      0.804196  0.730769       0.791667    0.804196  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Resultados_SVM = pd.DataFrame(np.column_stack((parametro, np.array(metricas_entreno), \n",
    "                                           np.array(metricas_validacion))), \n",
    "                          columns = ['Parametro',  'Accuracy_Entreno', 'f1_Entreno', 'Precision_Entreno', \n",
    "                                     'Recall_Entreno', 'Accuracy_Val', 'f1_Val', 'Precision_Val', \n",
    "                                     'Recall_Val'])\n",
    "Resultados_SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Naive Bayes tomando los datos que trabajos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X_entreno, X_val, y_entreno, y_val, variables):\n",
    "    #Se trabaja con un clasificador Gausiano, especifico para estos modelos\n",
    "    modelo_NB = GaussianNB()\n",
    "    \n",
    "    modelo_NB.fit(X_entreno.values[:, variables], y_entreno.reshape(len(y_entreno),))\n",
    "    # Medidas de entreno y validación obtenidas por Sklearn\n",
    "    # Medidas de entreno\n",
    "    y_pred_e = modelo_NB.predict(X_entreno.values[:, variables])\n",
    "    y_pred_v = modelo_NB.predict(X_val.values[:, variables])\n",
    "    \n",
    "    \n",
    "    medidas_entreno = [mt.accuracy_score(y_entreno, y_pred_e, normalize=True), mt.f1_score(y_entreno, y_pred_e), \n",
    "                       mt.precision_score(y_entreno, y_pred_e), \n",
    "                       mt.recall_score(y_entreno, y_pred_e, average='weighted')]\n",
    "    #Medidas de validación\n",
    "    medidas_validacion = [mt.accuracy_score(y_val, y_pred_v, normalize=True), mt.f1_score(y_val, y_pred_v), \n",
    "                          mt.precision_score(y_val, y_pred_v), \n",
    "                          mt.recall_score(y_val, y_pred_v, average='weighted')]\n",
    "    \n",
    "    return modelo_NB, medidas_entreno, medidas_validacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_entreno = []\n",
    "metricas_validacion = []\n",
    "lista1=[[0,1,2,3,4,5],[0,1,2,3,4,5,6],\n",
    "        [1,2,3,4,5,6,7,8], [0,1,3,5,6,8,9,10],[1,3,4,5,6,7,8,9],[0,1,4,5,6,8,9,10],[0,1,2,4,6,7,8,10],\n",
    "        [1,2,3,4,5,7,8,9,10], [0,1,3,5,6,7,8,9,10], [1,2,3,5,6,7,8,9,10]]\n",
    "\n",
    "for i in lista1: \n",
    "    _, metrica_e, metrica_v = naive_bayes(X_entreno, X_val, y_entreno, y_val, i)\n",
    "    metricas_entreno.append(metrica_e)\n",
    "    metricas_validacion.append(metrica_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variables</th>\n",
       "      <th>Accuracy_Entreno</th>\n",
       "      <th>f1_Entreno</th>\n",
       "      <th>Precision_Entreno</th>\n",
       "      <th>Recall_Entreno</th>\n",
       "      <th>Accuracy_Val</th>\n",
       "      <th>f1_Val</th>\n",
       "      <th>Precision_Val</th>\n",
       "      <th>Recall_Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5]</td>\n",
       "      <td>0.810193</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.810193</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.743363</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.797203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>0.811951</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.811951</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.725664</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.783217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>0.796134</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.796134</td>\n",
       "      <td>0.79021</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.79021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 3, 5, 6, 8, 9, 10]</td>\n",
       "      <td>0.70123</td>\n",
       "      <td>0.538043</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.70123</td>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.49505</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.643357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0.787346</td>\n",
       "      <td>0.679045</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.787346</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.804196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 1, 4, 5, 6, 8, 9, 10]</td>\n",
       "      <td>0.766257</td>\n",
       "      <td>0.715203</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.766257</td>\n",
       "      <td>0.72028</td>\n",
       "      <td>0.69697</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.72028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 1, 2, 4, 6, 7, 8, 10]</td>\n",
       "      <td>0.780316</td>\n",
       "      <td>0.724062</td>\n",
       "      <td>0.680498</td>\n",
       "      <td>0.780316</td>\n",
       "      <td>0.72028</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.72028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5, 7, 8, 9, 10]</td>\n",
       "      <td>0.766257</td>\n",
       "      <td>0.679518</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.766257</td>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.755245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 1, 3, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0.697715</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.697715</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0.667838</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>0.667838</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.622378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Variables Accuracy_Entreno f1_Entreno Precision_Entreno  \\\n",
       "0            [0, 1, 2, 3, 4, 5]         0.810193   0.732673          0.770833   \n",
       "1         [0, 1, 2, 3, 4, 5, 6]         0.811951   0.735802          0.772021   \n",
       "2      [1, 2, 3, 4, 5, 6, 7, 8]         0.796134   0.718447              0.74   \n",
       "3     [0, 1, 3, 5, 6, 8, 9, 10]          0.70123   0.538043          0.634615   \n",
       "4      [1, 3, 4, 5, 6, 7, 8, 9]         0.787346   0.679045          0.775758   \n",
       "5     [0, 1, 4, 5, 6, 8, 9, 10]         0.766257   0.715203          0.654902   \n",
       "6     [0, 1, 2, 4, 6, 7, 8, 10]         0.780316   0.724062          0.680498   \n",
       "7  [1, 2, 3, 4, 5, 7, 8, 9, 10]         0.766257   0.679518          0.694581   \n",
       "8  [0, 1, 3, 5, 6, 7, 8, 9, 10]         0.697715   0.537634             0.625   \n",
       "9  [1, 2, 3, 5, 6, 7, 8, 9, 10]         0.667838   0.509091          0.566474   \n",
       "\n",
       "  Recall_Entreno Accuracy_Val    f1_Val Precision_Val Recall_Val  \n",
       "0       0.810193     0.797203  0.743363      0.736842   0.797203  \n",
       "1       0.811951     0.783217  0.725664      0.719298   0.783217  \n",
       "2       0.796134      0.79021  0.745763      0.709677    0.79021  \n",
       "3        0.70123     0.643357   0.49505      0.555556   0.643357  \n",
       "4       0.787346     0.804196  0.745455      0.759259   0.804196  \n",
       "5       0.766257      0.72028   0.69697      0.605263    0.72028  \n",
       "6       0.780316      0.72028  0.692308      0.608108    0.72028  \n",
       "7       0.766257     0.755245  0.710744      0.661538   0.755245  \n",
       "8       0.697715     0.615385  0.444444      0.511628   0.615385  \n",
       "9       0.667838     0.622378  0.470588      0.521739   0.622378  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaiveBayes_resultado = pd.DataFrame(np.column_stack((lista1, np.array(metricas_entreno), \n",
    "                                                     np.array(metricas_validacion))), \n",
    "                             columns = ['Variables', 'Accuracy_Entreno', 'f1_Entreno', 'Precision_Entreno', \n",
    "                                     'Recall_Entreno', 'Accuracy_Val', 'f1_Val', 'Precision_Val', \n",
    "                                     'Recall_Val'])\n",
    "NaiveBayes_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logistica\n",
    "\n",
    "Regresión Logistica tomando los datos que trabajos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion(X_entreno, X_val, y_entreno, y_val, lr, lambda_val, epochs, tag):\n",
    "    \n",
    "    # Definimos el tamaño de nuestras variables\n",
    "    w_ =[]\n",
    "    m, k = X_entreno.shape\n",
    "    tf.reset_default_graph()\n",
    "    gra = tf.Graph()\n",
    "    # Trabajamos el cascaron\n",
    "    with gra.as_default():\n",
    "        # Creando los placeholders que reciben las variables\n",
    "        X = tf.placeholder(tf.float32, shape = (None, k), name = \"X\")\n",
    "        Ylabels = tf.placeholder(tf.float32, name = \"Variables_y\")\n",
    "\n",
    "        # Tenemos el Learning Rate y Lambda como parametros del modelo (Hiperparametros)\n",
    "        lr_param = tf.placeholder(tf.float32, name = \"lr\")\n",
    "        lambda_param = tf.placeholder(tf.float32, name = \"lambda\")\n",
    "\n",
    "        # Los pesos de la regresión\n",
    "        # Coeficientes\n",
    "        W = tf.Variable(tf.truncated_normal(shape = [k, 1]), name = \"W\")\n",
    "        # Intercepto\n",
    "        b = tf.Variable(tf.truncated_normal(shape = (1, 1)), name = \"b\")\n",
    "        \n",
    "        # Definimos la regresión logistica\n",
    "        with tf.name_scope(\"Regresion\"):\n",
    "            Logits = tf.add(tf.matmul(X, W), b, name = \"Regresion\")\n",
    "            YlabelsHat = tf.nn.sigmoid(Logits)\n",
    "\n",
    "        # Función de costo\n",
    "        with tf.name_scope(\"Funcion_Costo\"):\n",
    "            w_norm = tf.divide(tf.multiply(tf.multiply(tf.constant(0.5), lambda_param), \n",
    "                                           tf.reduce_sum(tf.square(W))), tf.cast(m, tf.float32), \n",
    "                               name = \"W_norm\")\n",
    "            # Entropia cruzada\n",
    "            classif_term = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels = Ylabels, logits = Logits), name = \"CostoClasif\") \n",
    "            # Costo final, sumar la función de costo con la norma de los pesos\n",
    "            cost = tf.add(classif_term, w_norm, name=\"Costo\")\n",
    "\n",
    "        # Gradient Descent Optimizer - Solicitado en el proyecto\n",
    "        with tf.name_scope(\"Gradient_Descent_Optimizer\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(lr_param).minimize(cost) \n",
    "        \n",
    "        # Inicializador de variables globales\n",
    "        init = tf.global_variables_initializer() \n",
    "\n",
    "    with tf.Session(graph = gra) as sess:    \n",
    "        sess.run(init)        \n",
    "        for epoch in range(epochs):\n",
    "            # Corriendo los batch\n",
    "            _, c_ = sess.run([optimizer, cost], feed_dict = {X : X_entreno, Ylabels : y_entreno.reshape((m, 1)), \n",
    "                                                             lr_param : lr, lambda_param : lambda_val})\n",
    "            \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(\"Epoch: %d, \\t costo = %0.4f\" % (epoch+1, c_))\n",
    "            #Parametros finales, coeficientes e intercepto\n",
    "            w_, b_ = sess.run([W, b])\n",
    "                \n",
    "        # Devolver los parámetros\n",
    "        return w_, b_,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrica_regresion(w, b, X_entreno, y_entreno, X_val, y_val):\n",
    "    \n",
    "    # Predicción binaria\n",
    "    y_pred_e = 1.0*((1 / (1 + np.exp(-(np.matmul(X_entreno.values,w)+b)))) > 0.5)\n",
    "        \n",
    "    medidas_entreno = [mt.accuracy_score(y_entreno, y_pred_e, normalize=True), \n",
    "                           mt.f1_score(y_entreno, y_pred_e),mt.precision_score(y_entreno, y_pred_e), \n",
    "                           mt.recall_score(y_entreno, y_pred_e, average='weighted')]\n",
    "    \n",
    "    # Métricas en datos de entrenamiento\n",
    "    y_pred_v = 1.0*((1 / (1 + np.exp(-(np.matmul(X_val.values,w)+b)))) > 0.5)\n",
    "    medidas_validacion = [mt.accuracy_score(y_val, y_pred_v, normalize=True), \n",
    "                              mt.f1_score(y_val, y_pred_v), mt.precision_score(y_val, y_pred_v), \n",
    "                              mt.recall_score(y_val, y_pred_v, average='weighted')]\n",
    "    return medidas_entreno, medidas_validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marco/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/marco/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch: 100, \t costo = 0.8112\n",
      "Epoch: 200, \t costo = 0.8072\n",
      "Epoch: 300, \t costo = 0.8035\n",
      "Epoch: 400, \t costo = 0.7999\n",
      "Epoch: 500, \t costo = 0.7963\n",
      "Epoch: 600, \t costo = 0.7927\n",
      "Epoch: 700, \t costo = 0.7892\n",
      "Epoch: 800, \t costo = 0.7857\n",
      "Epoch: 900, \t costo = 0.7822\n",
      "Epoch: 1000, \t costo = 0.7788\n",
      "Epoch: 100, \t costo = 0.9313\n",
      "Epoch: 200, \t costo = 0.9273\n",
      "Epoch: 300, \t costo = 0.9235\n",
      "Epoch: 400, \t costo = 0.9197\n",
      "Epoch: 500, \t costo = 0.9160\n",
      "Epoch: 600, \t costo = 0.9123\n",
      "Epoch: 700, \t costo = 0.9086\n",
      "Epoch: 800, \t costo = 0.9050\n",
      "Epoch: 900, \t costo = 0.9015\n",
      "Epoch: 1000, \t costo = 0.8979\n",
      "Epoch: 100, \t costo = 0.6636\n",
      "Epoch: 200, \t costo = 0.6572\n",
      "Epoch: 300, \t costo = 0.6553\n",
      "Epoch: 400, \t costo = 0.6534\n",
      "Epoch: 500, \t costo = 0.6515\n",
      "Epoch: 600, \t costo = 0.6497\n",
      "Epoch: 700, \t costo = 0.6479\n",
      "Epoch: 800, \t costo = 0.6461\n",
      "Epoch: 900, \t costo = 0.6443\n",
      "Epoch: 1000, \t costo = 0.6426\n",
      "Epoch: 100, \t costo = 6.6667\n",
      "Epoch: 200, \t costo = 1.1477\n",
      "Epoch: 300, \t costo = 1.1413\n",
      "Epoch: 400, \t costo = 1.1349\n",
      "Epoch: 500, \t costo = 1.1285\n",
      "Epoch: 600, \t costo = 1.1222\n",
      "Epoch: 700, \t costo = 1.1159\n",
      "Epoch: 800, \t costo = 1.1097\n",
      "Epoch: 900, \t costo = 1.1034\n",
      "Epoch: 1000, \t costo = 1.0972\n",
      "Epoch: 100, \t costo = 0.8439\n",
      "Epoch: 200, \t costo = 0.8381\n",
      "Epoch: 300, \t costo = 0.8327\n",
      "Epoch: 400, \t costo = 0.8273\n",
      "Epoch: 500, \t costo = 0.8222\n",
      "Epoch: 600, \t costo = 0.8171\n",
      "Epoch: 700, \t costo = 0.8123\n",
      "Epoch: 800, \t costo = 0.8075\n",
      "Epoch: 900, \t costo = 0.8029\n",
      "Epoch: 1000, \t costo = 0.7983\n",
      "Epoch: 100, \t costo = 0.7746\n",
      "Epoch: 200, \t costo = 0.7691\n",
      "Epoch: 300, \t costo = 0.7638\n",
      "Epoch: 400, \t costo = 0.7587\n",
      "Epoch: 500, \t costo = 0.7537\n",
      "Epoch: 600, \t costo = 0.7489\n",
      "Epoch: 700, \t costo = 0.7441\n",
      "Epoch: 800, \t costo = 0.7395\n",
      "Epoch: 900, \t costo = 0.7349\n",
      "Epoch: 1000, \t costo = 0.7305\n",
      "Epoch: 100, \t costo = 3.5287\n",
      "Epoch: 200, \t costo = 1.0194\n",
      "Epoch: 300, \t costo = 0.8535\n",
      "Epoch: 400, \t costo = 0.8499\n",
      "Epoch: 500, \t costo = 0.8462\n",
      "Epoch: 600, \t costo = 0.8427\n",
      "Epoch: 700, \t costo = 0.8391\n",
      "Epoch: 800, \t costo = 0.8356\n",
      "Epoch: 900, \t costo = 0.8321\n",
      "Epoch: 1000, \t costo = 0.8286\n",
      "Epoch: 100, \t costo = 0.5910\n",
      "Epoch: 200, \t costo = 0.5899\n",
      "Epoch: 300, \t costo = 0.5888\n",
      "Epoch: 400, \t costo = 0.5877\n",
      "Epoch: 500, \t costo = 0.5866\n",
      "Epoch: 600, \t costo = 0.5856\n",
      "Epoch: 700, \t costo = 0.5845\n",
      "Epoch: 800, \t costo = 0.5835\n",
      "Epoch: 900, \t costo = 0.5825\n",
      "Epoch: 1000, \t costo = 0.5815\n",
      "Epoch: 100, \t costo = 0.8656\n",
      "Epoch: 200, \t costo = 0.8532\n",
      "Epoch: 300, \t costo = 0.8412\n",
      "Epoch: 400, \t costo = 0.8295\n",
      "Epoch: 500, \t costo = 0.8182\n",
      "Epoch: 600, \t costo = 0.8072\n",
      "Epoch: 700, \t costo = 0.7965\n",
      "Epoch: 800, \t costo = 0.7862\n",
      "Epoch: 900, \t costo = 0.7763\n",
      "Epoch: 1000, \t costo = 0.7667\n",
      "Epoch: 100, \t costo = 9.5679\n",
      "Epoch: 200, \t costo = 0.8629\n",
      "Epoch: 300, \t costo = 0.8576\n",
      "Epoch: 400, \t costo = 0.8524\n",
      "Epoch: 500, \t costo = 0.8473\n",
      "Epoch: 600, \t costo = 0.8423\n",
      "Epoch: 700, \t costo = 0.8373\n",
      "Epoch: 800, \t costo = 0.8325\n",
      "Epoch: 900, \t costo = 0.8276\n",
      "Epoch: 1000, \t costo = 0.8229\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Parmetros_lam =[0.1,0.5,1.,2.,3.,4.,5.,10.,15.,20.]\n",
    "    \n",
    "metricas_entreno = []\n",
    "metricas_validacion = []\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 0.1, 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 0.5, 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 1., 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 2., 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 3., 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 4., 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 5., 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 10., 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 15., 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 20., 1000, '')\n",
    "metrica_e, metrica_v = metrica_regresion(w_, b_, X_entreno, y_entreno, X_val, y_val)\n",
    "metricas_entreno.append(metrica_e)\n",
    "metricas_validacion.append(metrica_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Accuracy_Entreno</th>\n",
       "      <th>f1_Entreno</th>\n",
       "      <th>Precision_Entreno</th>\n",
       "      <th>Recall_Entreno</th>\n",
       "      <th>Accuracy_Val</th>\n",
       "      <th>f1_Val</th>\n",
       "      <th>Precision_Val</th>\n",
       "      <th>Recall_Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.585237</td>\n",
       "      <td>0.415842</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.585237</td>\n",
       "      <td>0.594406</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.594406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.616872</td>\n",
       "      <td>0.377143</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.616872</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.671353</td>\n",
       "      <td>0.547215</td>\n",
       "      <td>0.562189</td>\n",
       "      <td>0.671353</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.734266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.643234</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.643234</td>\n",
       "      <td>0.573427</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.573427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.579965</td>\n",
       "      <td>0.415648</td>\n",
       "      <td>0.431472</td>\n",
       "      <td>0.579965</td>\n",
       "      <td>0.580420</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.580420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.690685</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.690685</td>\n",
       "      <td>0.685315</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.685315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.604569</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.471616</td>\n",
       "      <td>0.604569</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.706503</td>\n",
       "      <td>0.532213</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.706503</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.622378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.659051</td>\n",
       "      <td>0.535885</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.659051</td>\n",
       "      <td>0.650350</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.650350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.687170</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.618056</td>\n",
       "      <td>0.687170</td>\n",
       "      <td>0.713287</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.713287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lambda  Accuracy_Entreno  f1_Entreno  Precision_Entreno  Recall_Entreno  \\\n",
       "0     0.1          0.585237    0.415842           0.437500        0.585237   \n",
       "1     0.5          0.616872    0.377143           0.478261        0.616872   \n",
       "2     1.0          0.671353    0.547215           0.562189        0.671353   \n",
       "3     2.0          0.643234    0.382979           0.538462        0.643234   \n",
       "4     3.0          0.579965    0.415648           0.431472        0.579965   \n",
       "5     4.0          0.690685    0.531915           0.609756        0.690685   \n",
       "6     5.0          0.604569    0.489796           0.471616        0.604569   \n",
       "7    10.0          0.706503    0.532213           0.655172        0.706503   \n",
       "8    15.0          0.659051    0.535885           0.543689        0.659051   \n",
       "9    20.0          0.687170    0.500000           0.618056        0.687170   \n",
       "\n",
       "   Accuracy_Val    f1_Val  Precision_Val  Recall_Val  \n",
       "0      0.594406  0.408163       0.476190    0.594406  \n",
       "1      0.538462  0.266667       0.352941    0.538462  \n",
       "2      0.734266  0.666667       0.655172    0.734266  \n",
       "3      0.573427  0.298851       0.419355    0.573427  \n",
       "4      0.580420  0.347826       0.444444    0.580420  \n",
       "5      0.685315  0.516129       0.648649    0.685315  \n",
       "6      0.671329  0.552381       0.591837    0.671329  \n",
       "7      0.622378  0.413043       0.527778    0.622378  \n",
       "8      0.650350  0.519231       0.562500    0.650350  \n",
       "9      0.713287  0.559140       0.702703    0.713287  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Regresion_resultado = pd.DataFrame(np.column_stack((Parmetros_lam, np.array(metricas_entreno), \n",
    "                                                     np.array(metricas_validacion))), \n",
    "                             columns = ['Lambda', 'Accuracy_Entreno', 'f1_Entreno', 'Precision_Entreno', \n",
    "                                     'Recall_Entreno', 'Accuracy_Val', 'f1_Val', 'Precision_Val', \n",
    "                                     'Recall_Val'])\n",
    "Regresion_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensambling Learning\n",
    "\n",
    "A continuación trabajaremos uniendo todos los modelos previamente trabajados en uno solo, para tomar la mejor desición, para realizar esto se toma una moda de los ejercicios que trabajamos, en este caso toma la moda de los 4 modelos planteados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lambda_Reg</th>\n",
       "      <th>Accuracy_Ent_Regresion</th>\n",
       "      <th>Accuracy_Val_Regresion</th>\n",
       "      <th>Variables_Bayes</th>\n",
       "      <th>Accuracy_Ent_Bayes</th>\n",
       "      <th>Accuracy_Val_Bayes</th>\n",
       "      <th>Parametro_SVM</th>\n",
       "      <th>Accuracy_Ent_SVM</th>\n",
       "      <th>Accuracy_Val_SVM</th>\n",
       "      <th>Profundidad_arbol</th>\n",
       "      <th>Accuracy_Ent_arbol</th>\n",
       "      <th>Accuracy_Val_arbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.585237</td>\n",
       "      <td>0.594406</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5]</td>\n",
       "      <td>0.810193</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.808436</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>2</td>\n",
       "      <td>0.799649</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.616872</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>0.811951</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>1</td>\n",
       "      <td>0.843585</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83304</td>\n",
       "      <td>0.832168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.671353</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>0.796134</td>\n",
       "      <td>0.79021</td>\n",
       "      <td>2</td>\n",
       "      <td>0.843585</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>4</td>\n",
       "      <td>0.838313</td>\n",
       "      <td>0.839161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.643234</td>\n",
       "      <td>0.573427</td>\n",
       "      <td>[0, 1, 3, 5, 6, 8, 9, 10]</td>\n",
       "      <td>0.70123</td>\n",
       "      <td>0.643357</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>5</td>\n",
       "      <td>0.855888</td>\n",
       "      <td>0.825175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.579965</td>\n",
       "      <td>0.58042</td>\n",
       "      <td>[1, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0.787346</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>4</td>\n",
       "      <td>0.848858</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>6</td>\n",
       "      <td>0.880492</td>\n",
       "      <td>0.79021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.690685</td>\n",
       "      <td>0.685315</td>\n",
       "      <td>[0, 1, 4, 5, 6, 8, 9, 10]</td>\n",
       "      <td>0.766257</td>\n",
       "      <td>0.72028</td>\n",
       "      <td>5</td>\n",
       "      <td>0.850615</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>7</td>\n",
       "      <td>0.892794</td>\n",
       "      <td>0.825175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.604569</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>[0, 1, 2, 4, 6, 7, 8, 10]</td>\n",
       "      <td>0.780316</td>\n",
       "      <td>0.72028</td>\n",
       "      <td>6</td>\n",
       "      <td>0.85413</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>8</td>\n",
       "      <td>0.906854</td>\n",
       "      <td>0.797203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.706503</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>[1, 2, 3, 4, 5, 7, 8, 9, 10]</td>\n",
       "      <td>0.766257</td>\n",
       "      <td>0.755245</td>\n",
       "      <td>7</td>\n",
       "      <td>0.859402</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>9</td>\n",
       "      <td>0.919156</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.659051</td>\n",
       "      <td>0.65035</td>\n",
       "      <td>[0, 1, 3, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0.697715</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>10</td>\n",
       "      <td>0.871705</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>10</td>\n",
       "      <td>0.926186</td>\n",
       "      <td>0.797203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>0.68717</td>\n",
       "      <td>0.713287</td>\n",
       "      <td>[1, 2, 3, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0.667838</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>15</td>\n",
       "      <td>0.869947</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>20</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>0.79021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lambda_Reg Accuracy_Ent_Regresion Accuracy_Val_Regresion  \\\n",
       "0        0.1               0.585237               0.594406   \n",
       "1        0.5               0.616872               0.538462   \n",
       "2          1               0.671353               0.734266   \n",
       "3          2               0.643234               0.573427   \n",
       "4          3               0.579965                0.58042   \n",
       "5          4               0.690685               0.685315   \n",
       "6          5               0.604569               0.671329   \n",
       "7         10               0.706503               0.622378   \n",
       "8         15               0.659051                0.65035   \n",
       "9         20                0.68717               0.713287   \n",
       "\n",
       "                Variables_Bayes Accuracy_Ent_Bayes Accuracy_Val_Bayes  \\\n",
       "0            [0, 1, 2, 3, 4, 5]           0.810193           0.797203   \n",
       "1         [0, 1, 2, 3, 4, 5, 6]           0.811951           0.783217   \n",
       "2      [1, 2, 3, 4, 5, 6, 7, 8]           0.796134            0.79021   \n",
       "3     [0, 1, 3, 5, 6, 8, 9, 10]            0.70123           0.643357   \n",
       "4      [1, 3, 4, 5, 6, 7, 8, 9]           0.787346           0.804196   \n",
       "5     [0, 1, 4, 5, 6, 8, 9, 10]           0.766257            0.72028   \n",
       "6     [0, 1, 2, 4, 6, 7, 8, 10]           0.780316            0.72028   \n",
       "7  [1, 2, 3, 4, 5, 7, 8, 9, 10]           0.766257           0.755245   \n",
       "8  [0, 1, 3, 5, 6, 7, 8, 9, 10]           0.697715           0.615385   \n",
       "9  [1, 2, 3, 5, 6, 7, 8, 9, 10]           0.667838           0.622378   \n",
       "\n",
       "  Parametro_SVM Accuracy_Ent_SVM Accuracy_Val_SVM Profundidad_arbol  \\\n",
       "0           0.1         0.808436         0.811189                 2   \n",
       "1             1         0.843585         0.839161                 3   \n",
       "2             2         0.843585         0.846154                 4   \n",
       "3             3           0.8471         0.839161                 5   \n",
       "4             4         0.848858         0.839161                 6   \n",
       "5             5         0.850615         0.839161                 7   \n",
       "6             6          0.85413         0.839161                 8   \n",
       "7             7         0.859402         0.832168                 9   \n",
       "8            10         0.871705         0.811189                10   \n",
       "9            15         0.869947         0.804196                20   \n",
       "\n",
       "  Accuracy_Ent_arbol Accuracy_Val_arbol  \n",
       "0           0.799649           0.818182  \n",
       "1            0.83304           0.832168  \n",
       "2           0.838313           0.839161  \n",
       "3           0.855888           0.825175  \n",
       "4           0.880492            0.79021  \n",
       "5           0.892794           0.825175  \n",
       "6           0.906854           0.797203  \n",
       "7           0.919156           0.818182  \n",
       "8           0.926186           0.797203  \n",
       "9           0.977153            0.79021  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.column_stack((Regresion_resultado['Lambda'],Regresion_resultado['Accuracy_Entreno'],\n",
    "                              Regresion_resultado['Accuracy_Val'],NaiveBayes_resultado['Variables'],\n",
    "                             NaiveBayes_resultado['Accuracy_Entreno'],NaiveBayes_resultado['Accuracy_Val'],\n",
    "                             Resultados_SVM['Parametro'],Resultados_SVM['Accuracy_Entreno'],\n",
    "                              Resultados_SVM['Accuracy_Val'],resultado_arbol['Profundidad'],\n",
    "                             resultado_arbol['Accuracy_Entreno'],resultado_arbol['Accuracy_Val'])),\n",
    "            columns=['Lambda_Reg', 'Accuracy_Ent_Regresion', 'Accuracy_Val_Regresion','Variables_Bayes',\n",
    "                     'Accuracy_Ent_Bayes', 'Accuracy_Val_Bayes','Parametro_SVM','Accuracy_Ent_SVM', \n",
    "                     'Accuracy_Val_SVM', 'Profundidad_arbol', 'Accuracy_Ent_arbol','Accuracy_Val_arbol'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con los datos de los modelos, se toman las siguientes conclusiones:\n",
    "\n",
    "Al resumir todos los modelos en la tabla arriba descrita se puede apreciar cual tiene mayor presición con base a los datos del Accuracy entre el entreno y la validación.\n",
    "\n",
    "### Regresión\n",
    "Se toma el modelo que tiene un lambda igual a 1.0 ya que presenta las mejores condiciones.\n",
    "\n",
    "### Naive Bayes\n",
    "Se toma el modelo que tiene las variables 1, 3, 4, 5, 6, 7, 8, 9 del modelo, ya que presenta mejores caracteristicas en el modelos.\n",
    "\n",
    "### SVM\n",
    "Se toma el modelo que tiene como parametro de elección 2 ya que presenta mejores resultados.\n",
    "\n",
    "### Árbolo de desición\n",
    "Se toma el modelo que presenta una profundidad del modelo equivalente a 4 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, \t costo = 7.9631\n",
      "Epoch: 200, \t costo = 0.8174\n",
      "Epoch: 300, \t costo = 0.8108\n",
      "Epoch: 400, \t costo = 0.8044\n",
      "Epoch: 500, \t costo = 0.7982\n",
      "Epoch: 600, \t costo = 0.7921\n",
      "Epoch: 700, \t costo = 0.7862\n",
      "Epoch: 800, \t costo = 0.7805\n",
      "Epoch: 900, \t costo = 0.7750\n",
      "Epoch: 1000, \t costo = 0.7696\n"
     ]
    }
   ],
   "source": [
    "arbol_validar, _, _ = arbol_segmentacion(X_entreno, X_val, y_entreno, y_val, 4)\n",
    "y_pred_arbol = arbol_validar.predict(X_val)\n",
    "\n",
    "svm_validar, _, _ = svm_funcion(X_entreno, X_val, y_entreno, y_val, 2)\n",
    "y_pred_SVM = svm_validar.predict(X_val)\n",
    "\n",
    "NB_validar, _, _ = naive_bayes(X_entreno, X_val, y_entreno, y_val, [1, 3, 4, 5, 6, 7, 8, 9])\n",
    "y_pred_NB = NB_validar.predict(X_val.values[:, [1, 3, 4, 5, 6, 7, 8, 9]])\n",
    "\n",
    "w_, b_ = regresion(X_entreno, X_val, y_entreno, y_val, 0.001, 1., 1000, '')\n",
    "y_pred_regre = 1.0*((1 / (1 + np.exp(-(np.matmul(X_val.values,w_)+b_)))) > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YVal</th>\n",
       "      <th>Àrbol</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Naive_Bayes</th>\n",
       "      <th>Regresión</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YVal  Àrbol  SVM  Naive_Bayes  Regresión\n",
       "133   0.0    0.0  0.0          0.0        0.0\n",
       "134   0.0    1.0  0.0          0.0        0.0\n",
       "135   1.0    1.0  1.0          1.0        0.0\n",
       "136   0.0    0.0  0.0          1.0        1.0\n",
       "137   0.0    1.0  1.0          1.0        1.0\n",
       "138   1.0    1.0  1.0          1.0        0.0\n",
       "139   0.0    0.0  0.0          0.0        0.0\n",
       "140   0.0    0.0  0.0          0.0        0.0\n",
       "141   0.0    0.0  0.0          0.0        0.0\n",
       "142   1.0    1.0  0.0          0.0        0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_arbol.shape, y_pred_svm.shape, y_pred_NB.shape, y_pred_regre[:,0]\n",
    "\n",
    "combinedResults = pd.DataFrame(np.column_stack([y_val, y_pred_arbol, y_pred_SVM, y_pred_NB, y_pred_regre[:,0]]), \n",
    "             columns=[\"YVal\", \"Àrbol\", \"SVM\", \"Naive_Bayes\", \"Regresión\"])\n",
    "\n",
    "combinedResults.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado Final de modelos evaluados\n",
    "\n",
    "Se obtendra el resultado de Accuracy para el modelo que trabajamos, a través de una moda para saber si nuestro resultado satisface con lo planteado en el ejercicio, que era tener al menos 80% de satisfacción en sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8531468531468531"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener la moda de las predicciones de los 4 modelos\n",
    "from scipy import stats\n",
    "combinedPred, _ = stats.mode(combinedResults.iloc[:,1:5].values, axis = 1)\n",
    "\n",
    "# Computar el accuracy combinado\n",
    "mt.accuracy_score(y_val, combinedPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Bootstrapping\n",
    "\n",
    "En pocas palabras consiste en partir de una serie de datos se parte la información para tener pequeños dataset para poder trabajaar los mismos, se puede realizar este ejercicio empleando remplazoas o no, dependiendo el enfoque, al hacer esto tendremos más datos con los cuales podremos obtener estimadores y llegar a tener una conclusión que respalde nuestra información.\n",
    "\n",
    "Para el caso de este proyecto se podría haber implementado algún ejercicio de Bootstrapping para selecionar más información de validación y generar modelos más robustos.\n",
    "\n",
    "\n",
    "## K-Fold\n",
    "\n",
    "Es lo que se conoce como validación cruzada, se emplea para evaluar resultados de un análisis estadistico para determinar y garantizar que son independientes de la partición entre datos de entrenamiento y prueba. Consiste en repetir los ejercicios con otras particiones de datos, se emplea sobre todo para la predicción.\n",
    "\n",
    "Su nombre proviene de dividir la muestra en k cantidades para poder determinar que el promedio de todos los k valores este dentro de los valores que nosotros esperamos y consideramos adecuados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "Trabajar con Feuturing Enginnering es interesante ya que permite reconocer la variables antes de trabajar con las mismas sirve como guia y permite obtener mejores resultados, en el caso de este modelo en particular lo interesante fue que por medio de hacer esto se pudo quitar algunas variables que no eran relevantes para nuestro ejercicio como lo eran el nombre por ejemplo.\n",
    "\n",
    "Se pudo trabajar también con one-hot encoding para poder cambiar nuestra variables categoricas a dummies para poder clasificar mejor nuestros datos, esto gracias a las facilidades que otorga python en especifico la libreria Sklearn, que resulta bastante completa.\n",
    "\n",
    "Se trabajo con cuatro modelos distintos entre si que tienen sus ventajas y desvetajas, al permitir trabajar con la libreria Sklear, facilito mucho entender el por que de algunos modelos, ya que en un par de lineas se podía apreciar los resultados, aplicando a estos su respectiva interpretación, mientras que para otros modelos como la regresión implica un conocimiento mayor de programación para llegar a un resultado.\n",
    "\n",
    "De los modelose en que presento mayor acierto fue el de SVM, que es algo interesante ya que estos modelos trabajan por medio de mínimizar las distancias que tenemos entre los dato para tener la mejor estimación y el modelo que genero los datos con menor certeza fue el de regresión.\n",
    "\n",
    "El trabajar con encoding que en esta caso consitio en la moda de todos los resultados que obtenido al realizar los ejercicios, encontramos un precisión alta, mayor al 85%, lo que muestra en conclusión que todos nuestros modelos presetan buenos resultados al validarlos y por lo tanto podemos concluir que con un 15% de incerteza nuestro modelo acertara a buenosresultados.\n",
    "\n",
    "Para trabajos de esta embergadura se podría tomar como guia los cursos en linea que ofrecen algunas universidades en los cuales no se tiene que programar el 100% del código sino ciertas partes fundamentales y lo que se valora más en estos cursos es la interpretación, o trabajar en equipos ya que en mi caso particular al tener un trabajo, el tiempo que tengo para hacer este tipo de proyectos es más corto por lo que podría emplear la calificación o apoyos que se dio en el primer curso que tuvimos de python en el cual se apoyaba en mayor medida.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
